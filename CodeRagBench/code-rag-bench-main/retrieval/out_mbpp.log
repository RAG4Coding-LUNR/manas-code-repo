nohup: ignoring input
INFO 07-10 20:38:53 [__init__.py:244] Automatically detected platform cuda.
2025-07-10 20:38:55 - Use pytorch device_name: cuda
2025-07-10 20:38:55 - Load pretrained SentenceTransformer: codesage/codesage-base-v2
2025-07-10 20:38:58 - Query prompt: None, Passage prompt: None
2025-07-10 20:38:58 - Query prompt name: None, Passage prompt name: None
2025-07-10 20:38:58 - Loading Corpus...
  0%|          | 0/34003 [00:00<?, ?it/s] 27%|██▋       | 9264/34003 [00:00<00:00, 92607.41it/s] 71%|███████   | 24089/34003 [00:00<00:00, 125316.63it/s]100%|██████████| 34003/34003 [00:00<00:00, 109626.83it/s]
2025-07-10 20:38:59 - Loaded 34003 TEST Documents.
2025-07-10 20:38:59 - Doc Example: {'text': 'tf.AggregationMethod     View source on GitHub    A class listing aggregation methods used to combine gradients.  View aliases  Compat aliases for migration \nSee Migration guide for more details. tf.compat.v1.AggregationMethod  Computing partial derivatives can require aggregating gradient contributions. This class lists the various methods that can be used to combine gradients in the graph. The following aggregation methods are part of the stable API for aggregating gradients:  \nADD_N: All of the gradient terms are summed as part of one operation using the "AddN" op (see tf.add_n). This method has the property that all gradients must be ready and buffered separately in memory before any aggregation is performed. \nDEFAULT: The system-chosen default aggregation method.  The following aggregation methods are experimental and may not be supported in future releases:  \nEXPERIMENTAL_TREE: Gradient terms are summed in pairs using using the "AddN" op. This method of summing gradients may reduce performance, but it can improve memory utilization because the gradients can be released earlier. \n \n\n\n Class Variables\n  ADD_N   0  \n  DEFAULT   0  \n  EXPERIMENTAL_ACCUMULATE_N   2  \n  EXPERIMENTAL_TREE   1', 'title': 'tensorflow.aggregationmethod'}
2025-07-10 20:38:59 - Loading Queries...
2025-07-10 20:38:59 - Loaded 269 TEST Queries.
2025-07-10 20:38:59 - Query Example: Problem:
I have following pandas dataframe :


import pandas as pd
from pandas import Series, DataFrame
data = DataFrame({'Qu1': ['apple', 'potato', 'cheese', 'banana', 'cheese', 'banana', 'cheese', 'potato', 'egg'],
              'Qu2': ['sausage', 'banana', 'apple', 'apple', 'apple', 'sausage', 'banana', 'banana', 'banana'],
              'Qu3': ['apple', 'potato', 'sausage', 'cheese', 'cheese', 'potato', 'cheese', 'potato', 'egg']})


I'd like to change values in columns Qu1 according to value_counts() when value count great or equal 3 and change values in columns Qu2 and Qu3 according to value_counts() when value count great or equal 2.
For example for Qu1 column
>>> pd.value_counts(data.Qu1) >= 3
cheese     True
potato    False
banana    False
apple     False
egg       False


I'd like to keep values cheese because each value has at least three appearances.
From values potato, banana, apple and egg I'd like to create value others
However I want to reserve all the 'apple'. That means don't replace 'apple' with 'other' and only 'egg' should be replaced.
For column Qu2 no changes :
>>> pd.value_counts(data.Qu2) >= 2
banana     True
apple      True
sausage   True


The final result as in attached test_data
test_data = DataFrame({'Qu1': ['apple', 'other', 'cheese', 'other', 'cheese', 'other', 'cheese', 'other', 'other'],
                   'Qu2': ['sausage', 'banana', 'apple', 'apple', 'apple', 'sausage', 'banana', 'banana', 'banana'],
                  'Qu3': ['apple', 'potato', 'other', 'cheese', 'cheese', 'potato', 'cheese', 'potato', 'other']})


Thanks !




A:
<code>
import pandas as pd


df = pd.DataFrame({'Qu1': ['apple', 'potato', 'cheese', 'banana', 'cheese', 'banana', 'cheese', 'potato', 'egg'],
                   'Qu2': ['sausage', 'banana', 'apple', 'apple', 'apple', 'sausage', 'banana', 'banana', 'banana'],
                   'Qu3': ['apple', 'potato', 'sausage', 'cheese', 'cheese', 'potato', 'cheese', 'potato', 'egg']})
</code>
result = ... # put solution in this variable
BEGIN SOLUTION
<code>

2025-07-10 20:38:59 - Encoding Queries...
Batches:   0%|          | 0/5 [00:00<?, ?it/s]Batches:  20%|██        | 1/5 [00:03<00:13,  3.42s/it]Batches:  40%|████      | 2/5 [00:03<00:04,  1.47s/it]Batches:  60%|██████    | 3/5 [00:04<00:02,  1.38s/it]Batches:  80%|████████  | 4/5 [00:05<00:01,  1.14s/it]Batches: 100%|██████████| 5/5 [00:05<00:00,  1.21it/s]Batches: 100%|██████████| 5/5 [00:05<00:00,  1.17s/it]
2025-07-10 20:39:05 - Sorting Corpus by document length (Longest first)...
2025-07-10 20:39:05 - Encoding Corpus in batches... Warning: This might take a while!
2025-07-10 20:39:05 - Scoring Function: Dot Product (dot)
2025-07-10 20:39:05 - Encoding Batch 1/1...
Batches:   0%|          | 0/532 [00:00<?, ?it/s]Batches:   0%|          | 1/532 [00:06<56:08,  6.34s/it]Batches:   0%|          | 2/532 [00:11<51:03,  5.78s/it]Batches:   1%|          | 3/532 [00:16<48:46,  5.53s/it]Batches:   1%|          | 4/532 [00:20<40:53,  4.65s/it]Batches:   1%|          | 5/532 [00:23<35:56,  4.09s/it]Batches:   1%|          | 6/532 [00:26<32:57,  3.76s/it]Batches:   1%|▏         | 7/532 [00:29<31:04,  3.55s/it]Batches:   2%|▏         | 8/532 [00:32<29:50,  3.42s/it]Batches:   2%|▏         | 9/532 [00:35<28:59,  3.33s/it]Batches:   2%|▏         | 10/532 [00:38<28:24,  3.27s/it]Batches:   2%|▏         | 11/532 [00:42<28:00,  3.22s/it]Batches:   2%|▏         | 12/532 [00:45<27:43,  3.20s/it]Batches:   2%|▏         | 13/532 [00:48<27:30,  3.18s/it]Batches:   3%|▎         | 14/532 [00:51<27:22,  3.17s/it]Batches:   3%|▎         | 15/532 [00:54<27:16,  3.16s/it]Batches:   3%|▎         | 16/532 [00:57<27:11,  3.16s/it]Batches:   3%|▎         | 17/532 [01:01<27:07,  3.16s/it]Batches:   3%|▎         | 18/532 [01:04<27:04,  3.16s/it]Batches:   4%|▎         | 19/532 [01:07<27:02,  3.16s/it]Batches:   4%|▍         | 20/532 [01:10<26:59,  3.16s/it]Batches:   4%|▍         | 21/532 [01:13<26:58,  3.17s/it]Batches:   4%|▍         | 22/532 [01:16<26:56,  3.17s/it]Batches:   4%|▍         | 23/532 [01:20<26:53,  3.17s/it]Batches:   5%|▍         | 24/532 [01:23<26:52,  3.17s/it]Batches:   5%|▍         | 25/532 [01:26<26:50,  3.18s/it]Batches:   5%|▍         | 26/532 [01:29<26:48,  3.18s/it]Batches:   5%|▌         | 27/532 [01:32<26:47,  3.18s/it]Batches:   5%|▌         | 28/532 [01:35<26:45,  3.19s/it]Batches:   5%|▌         | 29/532 [01:39<26:43,  3.19s/it]Batches:   6%|▌         | 30/532 [01:42<26:41,  3.19s/it]Batches:   6%|▌         | 31/532 [01:45<26:38,  3.19s/it]Batches:   6%|▌         | 32/532 [01:48<26:36,  3.19s/it]Batches:   6%|▌         | 33/532 [01:51<26:33,  3.19s/it]Batches:   6%|▋         | 34/532 [01:55<26:31,  3.20s/it]Batches:   7%|▋         | 35/532 [01:58<26:29,  3.20s/it]Batches:   7%|▋         | 36/532 [02:01<26:26,  3.20s/it]Batches:   7%|▋         | 37/532 [02:04<26:23,  3.20s/it]Batches:   7%|▋         | 38/532 [02:07<26:20,  3.20s/it]Batches:   7%|▋         | 39/532 [02:11<26:17,  3.20s/it]Batches:   8%|▊         | 40/532 [02:14<26:14,  3.20s/it]Batches:   8%|▊         | 41/532 [02:17<26:11,  3.20s/it]Batches:   8%|▊         | 42/532 [02:20<26:09,  3.20s/it]Batches:   8%|▊         | 43/532 [02:23<26:06,  3.20s/it]Batches:   8%|▊         | 44/532 [02:27<26:04,  3.21s/it]Batches:   8%|▊         | 45/532 [02:30<26:01,  3.21s/it]Batches:   9%|▊         | 46/532 [02:33<25:59,  3.21s/it]Batches:   9%|▉         | 47/532 [02:36<25:56,  3.21s/it]Batches:   9%|▉         | 48/532 [02:40<25:53,  3.21s/it]Batches:   9%|▉         | 49/532 [02:43<25:50,  3.21s/it]Batches:   9%|▉         | 50/532 [02:46<25:46,  3.21s/it]Batches:  10%|▉         | 51/532 [02:49<25:44,  3.21s/it]Batches:  10%|▉         | 52/532 [02:52<25:23,  3.17s/it]Batches:  10%|▉         | 53/532 [02:55<25:25,  3.18s/it]Batches:  10%|█         | 54/532 [02:58<24:58,  3.14s/it]Batches:  10%|█         | 55/532 [03:02<25:07,  3.16s/it]Batches:  11%|█         | 56/532 [03:05<24:49,  3.13s/it]Batches:  11%|█         | 57/532 [03:08<24:34,  3.10s/it]Batches:  11%|█         | 58/532 [03:11<24:46,  3.14s/it]Batches:  11%|█         | 59/532 [03:14<24:54,  3.16s/it]Batches:  11%|█▏        | 60/532 [03:17<24:58,  3.18s/it]Batches:  11%|█▏        | 61/532 [03:20<23:57,  3.05s/it]Batches:  12%|█▏        | 62/532 [03:23<22:31,  2.88s/it]Batches:  12%|█▏        | 63/532 [03:26<23:15,  2.98s/it]Batches:  12%|█▏        | 64/532 [03:29<23:13,  2.98s/it]Batches:  12%|█▏        | 65/532 [03:32<23:43,  3.05s/it]Batches:  12%|█▏        | 66/532 [03:34<21:53,  2.82s/it]Batches:  13%|█▎        | 67/532 [03:37<22:20,  2.88s/it]Batches:  13%|█▎        | 68/532 [03:41<23:04,  2.98s/it]Batches:  13%|█▎        | 69/532 [03:44<23:14,  3.01s/it]Batches:  13%|█▎        | 70/532 [03:46<22:17,  2.89s/it]Batches:  13%|█▎        | 71/532 [03:49<21:45,  2.83s/it]Batches:  14%|█▎        | 72/532 [03:52<21:59,  2.87s/it]Batches:  14%|█▎        | 73/532 [03:55<22:33,  2.95s/it]Batches:  14%|█▍        | 74/532 [03:58<21:49,  2.86s/it]Batches:  14%|█▍        | 75/532 [04:01<22:35,  2.97s/it]Batches:  14%|█▍        | 76/532 [04:03<20:57,  2.76s/it]Batches:  14%|█▍        | 77/532 [04:06<20:53,  2.75s/it]Batches:  15%|█▍        | 78/532 [04:08<19:33,  2.58s/it]Batches:  15%|█▍        | 79/532 [04:11<19:10,  2.54s/it]Batches:  15%|█▌        | 80/532 [04:13<18:38,  2.47s/it]Batches:  15%|█▌        | 81/532 [04:15<18:00,  2.40s/it]Batches:  15%|█▌        | 82/532 [04:18<19:26,  2.59s/it]Batches:  16%|█▌        | 83/532 [04:20<18:00,  2.41s/it]Batches:  16%|█▌        | 84/532 [04:22<17:16,  2.31s/it]Batches:  16%|█▌        | 85/532 [04:24<17:07,  2.30s/it]Batches:  16%|█▌        | 86/532 [04:26<15:58,  2.15s/it]Batches:  16%|█▋        | 87/532 [04:28<15:50,  2.14s/it]Batches:  17%|█▋        | 88/532 [04:31<17:05,  2.31s/it]Batches:  17%|█▋        | 89/532 [04:33<16:36,  2.25s/it]Batches:  17%|█▋        | 90/532 [04:35<16:06,  2.19s/it]Batches:  17%|█▋        | 91/532 [04:38<17:12,  2.34s/it]Batches:  17%|█▋        | 92/532 [04:40<16:23,  2.23s/it]Batches:  17%|█▋        | 93/532 [04:42<15:24,  2.11s/it]Batches:  18%|█▊        | 94/532 [04:44<14:40,  2.01s/it]Batches:  18%|█▊        | 95/532 [04:46<14:44,  2.02s/it]Batches:  18%|█▊        | 96/532 [04:47<14:13,  1.96s/it]Batches:  18%|█▊        | 97/532 [04:49<13:35,  1.87s/it]Batches:  18%|█▊        | 98/532 [04:51<13:05,  1.81s/it]Batches:  19%|█▊        | 99/532 [04:52<12:54,  1.79s/it]Batches:  19%|█▉        | 100/532 [04:54<12:42,  1.77s/it]Batches:  19%|█▉        | 101/532 [04:56<12:55,  1.80s/it]Batches:  19%|█▉        | 102/532 [04:58<12:39,  1.77s/it]Batches:  19%|█▉        | 103/532 [04:59<12:27,  1.74s/it]Batches:  20%|█▉        | 104/532 [05:01<12:19,  1.73s/it]Batches:  20%|█▉        | 105/532 [05:03<12:56,  1.82s/it]Batches:  20%|█▉        | 106/532 [05:05<13:34,  1.91s/it]Batches:  20%|██        | 107/532 [05:07<12:31,  1.77s/it]Batches:  20%|██        | 108/532 [05:08<12:27,  1.76s/it]Batches:  20%|██        | 109/532 [05:10<12:40,  1.80s/it]Batches:  21%|██        | 110/532 [05:12<12:26,  1.77s/it]Batches:  21%|██        | 111/532 [05:13<11:31,  1.64s/it]Batches:  21%|██        | 112/532 [05:15<11:16,  1.61s/it]Batches:  21%|██        | 113/532 [05:17<12:20,  1.77s/it]Batches:  21%|██▏       | 114/532 [05:18<11:30,  1.65s/it]Batches:  22%|██▏       | 115/532 [05:20<11:13,  1.62s/it]Batches:  22%|██▏       | 116/532 [05:22<11:13,  1.62s/it]Batches:  22%|██▏       | 117/532 [05:23<10:51,  1.57s/it]Batches:  22%|██▏       | 118/532 [05:24<10:10,  1.48s/it]Batches:  22%|██▏       | 119/532 [05:26<10:32,  1.53s/it]Batches:  23%|██▎       | 120/532 [05:28<10:32,  1.54s/it]Batches:  23%|██▎       | 121/532 [05:29<10:43,  1.57s/it]Batches:  23%|██▎       | 122/532 [05:30<10:02,  1.47s/it]Batches:  23%|██▎       | 123/532 [05:32<09:47,  1.44s/it]Batches:  23%|██▎       | 124/532 [05:33<09:23,  1.38s/it]Batches:  23%|██▎       | 125/532 [05:34<09:06,  1.34s/it]Batches:  24%|██▎       | 126/532 [05:36<08:54,  1.32s/it]Batches:  24%|██▍       | 127/532 [05:37<08:49,  1.31s/it]Batches:  24%|██▍       | 128/532 [05:38<09:05,  1.35s/it]Batches:  24%|██▍       | 129/532 [05:39<08:46,  1.31s/it]Batches:  24%|██▍       | 130/532 [05:41<08:57,  1.34s/it]Batches:  25%|██▍       | 131/532 [05:42<08:41,  1.30s/it]Batches:  25%|██▍       | 132/532 [05:43<08:33,  1.28s/it]Batches:  25%|██▌       | 133/532 [05:45<08:26,  1.27s/it]Batches:  25%|██▌       | 134/532 [05:46<08:07,  1.22s/it]Batches:  25%|██▌       | 135/532 [05:47<08:31,  1.29s/it]Batches:  26%|██▌       | 136/532 [05:49<08:41,  1.32s/it]Batches:  26%|██▌       | 137/532 [05:50<08:25,  1.28s/it]Batches:  26%|██▌       | 138/532 [05:51<08:17,  1.26s/it]Batches:  26%|██▌       | 139/532 [05:52<08:12,  1.25s/it]Batches:  26%|██▋       | 140/532 [05:54<08:43,  1.34s/it]Batches:  27%|██▋       | 141/532 [05:55<08:02,  1.23s/it]Batches:  27%|██▋       | 142/532 [05:56<07:44,  1.19s/it]Batches:  27%|██▋       | 143/532 [05:57<07:34,  1.17s/it]Batches:  27%|██▋       | 144/532 [05:58<07:08,  1.10s/it]Batches:  27%|██▋       | 145/532 [05:59<07:17,  1.13s/it]Batches:  27%|██▋       | 146/532 [06:00<06:56,  1.08s/it]Batches:  28%|██▊       | 147/532 [06:01<07:25,  1.16s/it]Batches:  28%|██▊       | 148/532 [06:02<07:03,  1.10s/it]Batches:  28%|██▊       | 149/532 [06:03<06:38,  1.04s/it]Batches:  28%|██▊       | 150/532 [06:04<06:25,  1.01s/it]Batches:  28%|██▊       | 151/532 [06:05<06:13,  1.02it/s]Batches:  29%|██▊       | 152/532 [06:06<06:13,  1.02it/s]Batches:  29%|██▉       | 153/532 [06:07<06:10,  1.02it/s]Batches:  29%|██▉       | 154/532 [06:08<06:24,  1.02s/it]Batches:  29%|██▉       | 155/532 [06:09<06:20,  1.01s/it]Batches:  29%|██▉       | 156/532 [06:10<06:15,  1.00it/s]Batches:  30%|██▉       | 157/532 [06:11<06:10,  1.01it/s]Batches:  30%|██▉       | 158/532 [06:12<06:07,  1.02it/s]Batches:  30%|██▉       | 159/532 [06:13<05:54,  1.05it/s]Batches:  30%|███       | 160/532 [06:14<06:14,  1.01s/it]Batches:  30%|███       | 161/532 [06:15<06:01,  1.03it/s]Batches:  30%|███       | 162/532 [06:16<06:00,  1.03it/s]Batches:  31%|███       | 163/532 [06:17<06:08,  1.00it/s]Batches:  31%|███       | 164/532 [06:18<06:03,  1.01it/s]Batches:  31%|███       | 165/532 [06:19<05:59,  1.02it/s]Batches:  31%|███       | 166/532 [06:20<05:49,  1.05it/s]Batches:  31%|███▏      | 167/532 [06:21<05:26,  1.12it/s]Batches:  32%|███▏      | 168/532 [06:21<05:20,  1.13it/s]Batches:  32%|███▏      | 169/532 [06:22<05:10,  1.17it/s]Batches:  32%|███▏      | 170/532 [06:23<04:58,  1.21it/s]Batches:  32%|███▏      | 171/532 [06:24<04:49,  1.25it/s]Batches:  32%|███▏      | 172/532 [06:25<04:56,  1.21it/s]Batches:  33%|███▎      | 173/532 [06:25<04:52,  1.23it/s]Batches:  33%|███▎      | 174/532 [06:26<05:05,  1.17it/s]Batches:  33%|███▎      | 175/532 [06:27<04:52,  1.22it/s]Batches:  33%|███▎      | 176/532 [06:28<04:52,  1.22it/s]Batches:  33%|███▎      | 177/532 [06:29<04:45,  1.24it/s]Batches:  33%|███▎      | 178/532 [06:30<04:59,  1.18it/s]Batches:  34%|███▎      | 179/532 [06:30<04:59,  1.18it/s]Batches:  34%|███▍      | 180/532 [06:31<05:09,  1.14it/s]Batches:  34%|███▍      | 181/532 [06:32<04:54,  1.19it/s]Batches:  34%|███▍      | 182/532 [06:33<05:05,  1.14it/s]Batches:  34%|███▍      | 183/532 [06:34<04:51,  1.20it/s]Batches:  35%|███▍      | 184/532 [06:35<04:40,  1.24it/s]Batches:  35%|███▍      | 185/532 [06:35<04:27,  1.30it/s]Batches:  35%|███▍      | 186/532 [06:36<04:24,  1.31it/s]Batches:  35%|███▌      | 187/532 [06:37<04:06,  1.40it/s]Batches:  35%|███▌      | 188/532 [06:37<04:08,  1.38it/s]Batches:  36%|███▌      | 189/532 [06:38<04:09,  1.38it/s]Batches:  36%|███▌      | 190/532 [06:39<04:09,  1.37it/s]Batches:  36%|███▌      | 191/532 [06:40<04:17,  1.32it/s]Batches:  36%|███▌      | 192/532 [06:40<04:18,  1.32it/s]Batches:  36%|███▋      | 193/532 [06:41<04:08,  1.37it/s]Batches:  36%|███▋      | 194/532 [06:42<03:55,  1.44it/s]Batches:  37%|███▋      | 195/532 [06:42<03:57,  1.42it/s]Batches:  37%|███▋      | 196/532 [06:43<04:04,  1.38it/s]Batches:  37%|███▋      | 197/532 [06:44<03:56,  1.42it/s]Batches:  37%|███▋      | 198/532 [06:44<03:49,  1.46it/s]Batches:  37%|███▋      | 199/532 [06:45<03:48,  1.46it/s]Batches:  38%|███▊      | 200/532 [06:46<03:48,  1.46it/s]Batches:  38%|███▊      | 201/532 [06:46<03:38,  1.51it/s]Batches:  38%|███▊      | 202/532 [06:47<03:29,  1.57it/s]Batches:  38%|███▊      | 203/532 [06:48<03:25,  1.60it/s]Batches:  38%|███▊      | 204/532 [06:48<03:15,  1.68it/s]Batches:  39%|███▊      | 205/532 [06:49<03:22,  1.62it/s]Batches:  39%|███▊      | 206/532 [06:49<03:19,  1.63it/s]Batches:  39%|███▉      | 207/532 [06:50<03:16,  1.65it/s]Batches:  39%|███▉      | 208/532 [06:51<03:11,  1.69it/s]Batches:  39%|███▉      | 209/532 [06:51<03:09,  1.71it/s]Batches:  39%|███▉      | 210/532 [06:52<03:02,  1.76it/s]Batches:  40%|███▉      | 211/532 [06:52<03:06,  1.72it/s]Batches:  40%|███▉      | 212/532 [06:53<03:01,  1.76it/s]Batches:  40%|████      | 213/532 [06:53<02:58,  1.79it/s]Batches:  40%|████      | 214/532 [06:54<03:04,  1.72it/s]Batches:  40%|████      | 215/532 [06:55<03:23,  1.56it/s]Batches:  41%|████      | 216/532 [06:56<03:35,  1.46it/s]Batches:  41%|████      | 217/532 [06:56<03:43,  1.41it/s]Batches:  41%|████      | 218/532 [06:57<03:22,  1.55it/s]Batches:  41%|████      | 219/532 [06:57<03:05,  1.69it/s]Batches:  41%|████▏     | 220/532 [06:58<02:55,  1.78it/s]Batches:  42%|████▏     | 221/532 [06:58<02:53,  1.79it/s]Batches:  42%|████▏     | 222/532 [06:59<02:52,  1.79it/s]Batches:  42%|████▏     | 223/532 [06:59<02:51,  1.81it/s]Batches:  42%|████▏     | 224/532 [07:00<02:49,  1.82it/s]Batches:  42%|████▏     | 225/532 [07:00<02:41,  1.90it/s]Batches:  42%|████▏     | 226/532 [07:01<02:43,  1.87it/s]Batches:  43%|████▎     | 227/532 [07:02<02:42,  1.88it/s]Batches:  43%|████▎     | 228/532 [07:02<02:39,  1.91it/s]Batches:  43%|████▎     | 229/532 [07:03<02:44,  1.85it/s]Batches:  43%|████▎     | 230/532 [07:03<02:44,  1.84it/s]Batches:  43%|████▎     | 231/532 [07:04<02:41,  1.86it/s]Batches:  44%|████▎     | 232/532 [07:04<02:47,  1.79it/s]Batches:  44%|████▍     | 233/532 [07:05<02:52,  1.74it/s]Batches:  44%|████▍     | 234/532 [07:05<02:52,  1.73it/s]Batches:  44%|████▍     | 235/532 [07:06<02:48,  1.76it/s]Batches:  44%|████▍     | 236/532 [07:07<02:45,  1.79it/s]Batches:  45%|████▍     | 237/532 [07:07<02:43,  1.80it/s]Batches:  45%|████▍     | 238/532 [07:08<02:32,  1.92it/s]Batches:  45%|████▍     | 239/532 [07:08<02:40,  1.82it/s]Batches:  45%|████▌     | 240/532 [07:09<02:38,  1.84it/s]Batches:  45%|████▌     | 241/532 [07:09<02:41,  1.80it/s]Batches:  45%|████▌     | 242/532 [07:10<02:34,  1.87it/s]Batches:  46%|████▌     | 243/532 [07:10<02:28,  1.94it/s]Batches:  46%|████▌     | 244/532 [07:11<02:48,  1.71it/s]Batches:  46%|████▌     | 245/532 [07:11<02:40,  1.79it/s]Batches:  46%|████▌     | 246/532 [07:12<02:29,  1.92it/s]Batches:  46%|████▋     | 247/532 [07:12<02:25,  1.96it/s]Batches:  47%|████▋     | 248/532 [07:13<02:14,  2.11it/s]Batches:  47%|████▋     | 249/532 [07:13<02:16,  2.08it/s]Batches:  47%|████▋     | 250/532 [07:14<02:07,  2.21it/s]Batches:  47%|████▋     | 251/532 [07:14<02:05,  2.24it/s]Batches:  47%|████▋     | 252/532 [07:15<02:10,  2.15it/s]Batches:  48%|████▊     | 253/532 [07:15<02:07,  2.20it/s]Batches:  48%|████▊     | 254/532 [07:15<02:07,  2.18it/s]Batches:  48%|████▊     | 255/532 [07:16<02:03,  2.24it/s]Batches:  48%|████▊     | 256/532 [07:16<02:08,  2.16it/s]Batches:  48%|████▊     | 257/532 [07:17<02:05,  2.19it/s]Batches:  48%|████▊     | 258/532 [07:17<02:02,  2.23it/s]Batches:  49%|████▊     | 259/532 [07:18<02:00,  2.26it/s]Batches:  49%|████▉     | 260/532 [07:18<02:06,  2.16it/s]Batches:  49%|████▉     | 261/532 [07:19<02:03,  2.19it/s]Batches:  49%|████▉     | 262/532 [07:19<02:03,  2.18it/s]Batches:  49%|████▉     | 263/532 [07:20<02:04,  2.17it/s]Batches:  50%|████▉     | 264/532 [07:20<02:07,  2.09it/s]Batches:  50%|████▉     | 265/532 [07:21<02:01,  2.20it/s]Batches:  50%|█████     | 266/532 [07:21<01:59,  2.22it/s]Batches:  50%|█████     | 267/532 [07:21<01:53,  2.34it/s]Batches:  50%|█████     | 268/532 [07:22<01:46,  2.47it/s]Batches:  51%|█████     | 269/532 [07:22<01:44,  2.53it/s]Batches:  51%|█████     | 270/532 [07:23<01:48,  2.41it/s]Batches:  51%|█████     | 271/532 [07:23<01:45,  2.48it/s]Batches:  51%|█████     | 272/532 [07:23<01:49,  2.37it/s]Batches:  51%|█████▏    | 273/532 [07:24<01:41,  2.54it/s]Batches:  52%|█████▏    | 274/532 [07:24<01:34,  2.74it/s]Batches:  52%|█████▏    | 275/532 [07:24<01:34,  2.73it/s]Batches:  52%|█████▏    | 276/532 [07:25<01:35,  2.69it/s]Batches:  52%|█████▏    | 277/532 [07:25<01:33,  2.72it/s]Batches:  52%|█████▏    | 278/532 [07:26<01:38,  2.58it/s]Batches:  52%|█████▏    | 279/532 [07:26<01:35,  2.65it/s]Batches:  53%|█████▎    | 280/532 [07:26<01:33,  2.70it/s]Batches:  53%|█████▎    | 281/532 [07:27<01:28,  2.83it/s]Batches:  53%|█████▎    | 282/532 [07:27<01:26,  2.90it/s]Batches:  53%|█████▎    | 283/532 [07:27<01:23,  2.97it/s]Batches:  53%|█████▎    | 284/532 [07:28<01:27,  2.85it/s]Batches:  54%|█████▎    | 285/532 [07:28<01:27,  2.83it/s]Batches:  54%|█████▍    | 286/532 [07:28<01:24,  2.91it/s]Batches:  54%|█████▍    | 287/532 [07:29<01:22,  2.98it/s]Batches:  54%|█████▍    | 288/532 [07:29<01:26,  2.81it/s]Batches:  54%|█████▍    | 289/532 [07:29<01:23,  2.92it/s]Batches:  55%|█████▍    | 290/532 [07:30<01:20,  2.99it/s]Batches:  55%|█████▍    | 291/532 [07:30<01:17,  3.09it/s]Batches:  55%|█████▍    | 292/532 [07:30<01:15,  3.19it/s]Batches:  55%|█████▌    | 293/532 [07:31<01:18,  3.05it/s]Batches:  55%|█████▌    | 294/532 [07:31<01:13,  3.22it/s]Batches:  55%|█████▌    | 295/532 [07:31<01:15,  3.12it/s]Batches:  56%|█████▌    | 296/532 [07:32<01:17,  3.06it/s]Batches:  56%|█████▌    | 297/532 [07:32<01:18,  2.99it/s]Batches:  56%|█████▌    | 298/532 [07:32<01:17,  3.03it/s]Batches:  56%|█████▌    | 299/532 [07:32<01:15,  3.07it/s]Batches:  56%|█████▋    | 300/532 [07:33<01:14,  3.10it/s]Batches:  57%|█████▋    | 301/532 [07:33<01:13,  3.12it/s]Batches:  57%|█████▋    | 302/532 [07:33<01:13,  3.11it/s]Batches:  57%|█████▋    | 303/532 [07:34<01:18,  2.94it/s]Batches:  57%|█████▋    | 304/532 [07:34<01:12,  3.13it/s]Batches:  57%|█████▋    | 305/532 [07:34<01:10,  3.22it/s]Batches:  58%|█████▊    | 306/532 [07:35<01:08,  3.32it/s]Batches:  58%|█████▊    | 307/532 [07:35<01:10,  3.19it/s]Batches:  58%|█████▊    | 308/532 [07:35<01:07,  3.30it/s]Batches:  58%|█████▊    | 309/532 [07:36<01:07,  3.32it/s]Batches:  58%|█████▊    | 310/532 [07:36<01:03,  3.47it/s]Batches:  58%|█████▊    | 311/532 [07:36<01:03,  3.47it/s]Batches:  59%|█████▊    | 312/532 [07:36<01:05,  3.34it/s]Batches:  59%|█████▉    | 313/532 [07:37<01:05,  3.32it/s]Batches:  59%|█████▉    | 314/532 [07:37<01:03,  3.43it/s]Batches:  59%|█████▉    | 315/532 [07:37<01:01,  3.53it/s]Batches:  59%|█████▉    | 316/532 [07:38<01:01,  3.50it/s]Batches:  60%|█████▉    | 317/532 [07:38<01:01,  3.48it/s]Batches:  60%|█████▉    | 318/532 [07:38<01:03,  3.35it/s]Batches:  60%|█████▉    | 319/532 [07:38<01:01,  3.47it/s]Batches:  60%|██████    | 320/532 [07:39<01:02,  3.40it/s]Batches:  60%|██████    | 321/532 [07:39<01:00,  3.51it/s]Batches:  61%|██████    | 322/532 [07:39<00:58,  3.62it/s]Batches:  61%|██████    | 323/532 [07:40<00:56,  3.70it/s]Batches:  61%|██████    | 324/532 [07:40<00:56,  3.70it/s]Batches:  61%|██████    | 325/532 [07:40<00:54,  3.79it/s]Batches:  61%|██████▏   | 326/532 [07:40<00:57,  3.56it/s]Batches:  61%|██████▏   | 327/532 [07:41<00:57,  3.54it/s]Batches:  62%|██████▏   | 328/532 [07:41<00:58,  3.52it/s]Batches:  62%|██████▏   | 329/532 [07:41<00:56,  3.57it/s]Batches:  62%|██████▏   | 330/532 [07:41<00:54,  3.71it/s]Batches:  62%|██████▏   | 331/532 [07:42<00:56,  3.57it/s]Batches:  62%|██████▏   | 332/532 [07:42<00:58,  3.43it/s]Batches:  63%|██████▎   | 333/532 [07:42<00:56,  3.53it/s]Batches:  63%|██████▎   | 334/532 [07:43<00:54,  3.63it/s]Batches:  63%|██████▎   | 335/532 [07:43<00:51,  3.79it/s]Batches:  63%|██████▎   | 336/532 [07:43<00:53,  3.69it/s]Batches:  63%|██████▎   | 337/532 [07:43<00:56,  3.43it/s]Batches:  64%|██████▎   | 338/532 [07:44<00:55,  3.52it/s]Batches:  64%|██████▎   | 339/532 [07:44<00:50,  3.80it/s]Batches:  64%|██████▍   | 340/532 [07:44<00:49,  3.84it/s]Batches:  64%|██████▍   | 341/532 [07:45<00:50,  3.77it/s]Batches:  64%|██████▍   | 342/532 [07:45<00:47,  4.00it/s]Batches:  64%|██████▍   | 343/532 [07:45<00:48,  3.93it/s]Batches:  65%|██████▍   | 344/532 [07:45<00:46,  4.01it/s]Batches:  65%|██████▍   | 345/532 [07:45<00:48,  3.88it/s]Batches:  65%|██████▌   | 346/532 [07:46<00:47,  3.94it/s]Batches:  65%|██████▌   | 347/532 [07:46<00:46,  3.97it/s]Batches:  65%|██████▌   | 348/532 [07:46<00:46,  3.99it/s]Batches:  66%|██████▌   | 349/532 [07:46<00:45,  4.06it/s]Batches:  66%|██████▌   | 350/532 [07:47<00:43,  4.22it/s]Batches:  66%|██████▌   | 351/532 [07:47<00:49,  3.65it/s]Batches:  66%|██████▌   | 352/532 [07:47<00:47,  3.76it/s]Batches:  66%|██████▋   | 353/532 [07:48<00:46,  3.85it/s]Batches:  67%|██████▋   | 354/532 [07:48<00:46,  3.80it/s]Batches:  67%|██████▋   | 355/532 [07:48<00:45,  3.92it/s]Batches:  67%|██████▋   | 356/532 [07:48<00:44,  3.96it/s]Batches:  67%|██████▋   | 357/532 [07:49<00:44,  3.96it/s]Batches:  67%|██████▋   | 358/532 [07:49<00:43,  3.98it/s]Batches:  67%|██████▋   | 359/532 [07:49<00:42,  4.03it/s]Batches:  68%|██████▊   | 360/532 [07:49<00:43,  3.93it/s]Batches:  68%|██████▊   | 361/532 [07:50<00:41,  4.17it/s]Batches:  68%|██████▊   | 362/532 [07:50<00:39,  4.34it/s]Batches:  68%|██████▊   | 363/532 [07:50<00:43,  3.88it/s]Batches:  68%|██████▊   | 364/532 [07:50<00:44,  3.77it/s]Batches:  69%|██████▊   | 365/532 [07:51<00:42,  3.92it/s]Batches:  69%|██████▉   | 366/532 [07:51<00:40,  4.12it/s]Batches:  69%|██████▉   | 367/532 [07:51<00:37,  4.43it/s]Batches:  69%|██████▉   | 368/532 [07:51<00:35,  4.57it/s]Batches:  69%|██████▉   | 369/532 [07:51<00:37,  4.40it/s]Batches:  70%|██████▉   | 370/532 [07:52<00:39,  4.10it/s]Batches:  70%|██████▉   | 371/532 [07:52<00:37,  4.32it/s]Batches:  70%|██████▉   | 372/532 [07:52<00:36,  4.41it/s]Batches:  70%|███████   | 373/532 [07:52<00:35,  4.52it/s]Batches:  70%|███████   | 374/532 [07:53<00:35,  4.41it/s]Batches:  70%|███████   | 375/532 [07:53<00:34,  4.50it/s]Batches:  71%|███████   | 376/532 [07:53<00:37,  4.15it/s]Batches:  71%|███████   | 377/532 [07:53<00:35,  4.32it/s]Batches:  71%|███████   | 378/532 [07:53<00:34,  4.45it/s]Batches:  71%|███████   | 379/532 [07:54<00:32,  4.65it/s]Batches:  71%|███████▏  | 380/532 [07:54<00:32,  4.68it/s]Batches:  72%|███████▏  | 381/532 [07:54<00:32,  4.69it/s]Batches:  72%|███████▏  | 382/532 [07:54<00:31,  4.76it/s]Batches:  72%|███████▏  | 383/532 [07:54<00:30,  4.82it/s]Batches:  72%|███████▏  | 384/532 [07:55<00:30,  4.81it/s]Batches:  72%|███████▏  | 385/532 [07:55<00:30,  4.82it/s]Batches:  73%|███████▎  | 386/532 [07:55<00:30,  4.86it/s]Batches:  73%|███████▎  | 387/532 [07:55<00:29,  4.84it/s]Batches:  73%|███████▎  | 388/532 [07:56<00:29,  4.85it/s]Batches:  73%|███████▎  | 389/532 [07:56<00:28,  4.93it/s]Batches:  73%|███████▎  | 390/532 [07:56<00:27,  5.23it/s]Batches:  73%|███████▎  | 391/532 [07:56<00:27,  5.21it/s]Batches:  74%|███████▎  | 392/532 [07:56<00:26,  5.34it/s]Batches:  74%|███████▍  | 393/532 [07:56<00:26,  5.16it/s]Batches:  74%|███████▍  | 394/532 [07:57<00:26,  5.23it/s]Batches:  74%|███████▍  | 395/532 [07:57<00:26,  5.12it/s]Batches:  74%|███████▍  | 396/532 [07:57<00:27,  5.03it/s]Batches:  75%|███████▍  | 397/532 [07:57<00:27,  4.92it/s]Batches:  75%|███████▍  | 398/532 [07:57<00:25,  5.23it/s]Batches:  75%|███████▌  | 399/532 [07:58<00:25,  5.13it/s]Batches:  75%|███████▌  | 400/532 [07:58<00:26,  5.05it/s]Batches:  75%|███████▌  | 401/532 [07:58<00:26,  5.00it/s]Batches:  76%|███████▌  | 402/532 [07:58<00:25,  5.11it/s]Batches:  76%|███████▌  | 403/532 [07:58<00:25,  5.04it/s]Batches:  76%|███████▌  | 404/532 [07:59<00:25,  4.99it/s]Batches:  76%|███████▌  | 405/532 [07:59<00:24,  5.15it/s]Batches:  76%|███████▋  | 406/532 [07:59<00:23,  5.26it/s]Batches:  77%|███████▋  | 407/532 [07:59<00:23,  5.39it/s]Batches:  77%|███████▋  | 408/532 [07:59<00:23,  5.32it/s]Batches:  77%|███████▋  | 409/532 [08:00<00:23,  5.21it/s]Batches:  77%|███████▋  | 410/532 [08:00<00:23,  5.21it/s]Batches:  77%|███████▋  | 411/532 [08:00<00:21,  5.52it/s]Batches:  77%|███████▋  | 412/532 [08:00<00:21,  5.46it/s]Batches:  78%|███████▊  | 413/532 [08:00<00:22,  5.30it/s]Batches:  78%|███████▊  | 414/532 [08:00<00:21,  5.41it/s]Batches:  78%|███████▊  | 415/532 [08:01<00:21,  5.48it/s]Batches:  78%|███████▊  | 416/532 [08:01<00:21,  5.51it/s]Batches:  78%|███████▊  | 417/532 [08:01<00:21,  5.32it/s]Batches:  79%|███████▊  | 418/532 [08:01<00:20,  5.49it/s]Batches:  79%|███████▉  | 419/532 [08:01<00:20,  5.52it/s]Batches:  79%|███████▉  | 420/532 [08:02<00:20,  5.41it/s]Batches:  79%|███████▉  | 421/532 [08:02<00:19,  5.78it/s]Batches:  79%|███████▉  | 422/532 [08:02<00:18,  5.81it/s]Batches:  80%|███████▉  | 423/532 [08:02<00:17,  6.06it/s]Batches:  80%|███████▉  | 424/532 [08:02<00:17,  6.10it/s]Batches:  80%|███████▉  | 425/532 [08:02<00:18,  5.80it/s]Batches:  80%|████████  | 426/532 [08:03<00:18,  5.60it/s]Batches:  80%|████████  | 427/532 [08:03<00:18,  5.60it/s]Batches:  80%|████████  | 428/532 [08:03<00:17,  5.79it/s]Batches:  81%|████████  | 429/532 [08:03<00:17,  5.88it/s]Batches:  81%|████████  | 430/532 [08:03<00:16,  6.25it/s]Batches:  81%|████████  | 431/532 [08:03<00:16,  6.05it/s]Batches:  81%|████████  | 432/532 [08:04<00:16,  6.16it/s]Batches:  81%|████████▏ | 433/532 [08:04<00:15,  6.24it/s]Batches:  82%|████████▏ | 434/532 [08:04<00:15,  6.13it/s]Batches:  82%|████████▏ | 435/532 [08:04<00:15,  6.18it/s]Batches:  82%|████████▏ | 436/532 [08:04<00:15,  6.15it/s]Batches:  82%|████████▏ | 437/532 [08:04<00:15,  6.31it/s]Batches:  82%|████████▏ | 438/532 [08:05<00:15,  6.00it/s]Batches:  83%|████████▎ | 439/532 [08:05<00:15,  5.93it/s]Batches:  83%|████████▎ | 440/532 [08:05<00:16,  5.75it/s]Batches:  83%|████████▎ | 441/532 [08:05<00:16,  5.63it/s]Batches:  83%|████████▎ | 442/532 [08:05<00:14,  6.10it/s]Batches:  83%|████████▎ | 443/532 [08:05<00:14,  6.15it/s]Batches:  83%|████████▎ | 444/532 [08:06<00:14,  6.23it/s]Batches:  84%|████████▎ | 445/532 [08:06<00:13,  6.39it/s]Batches:  84%|████████▍ | 446/532 [08:06<00:14,  6.05it/s]Batches:  84%|████████▍ | 447/532 [08:06<00:13,  6.29it/s]Batches:  84%|████████▍ | 448/532 [08:06<00:14,  5.97it/s]Batches:  84%|████████▍ | 449/532 [08:06<00:13,  6.21it/s]Batches:  85%|████████▍ | 450/532 [08:07<00:13,  6.07it/s]Batches:  85%|████████▍ | 451/532 [08:07<00:13,  6.17it/s]Batches:  85%|████████▍ | 452/532 [08:07<00:12,  6.36it/s]Batches:  85%|████████▌ | 453/532 [08:07<00:11,  6.78it/s]Batches:  85%|████████▌ | 454/532 [08:07<00:11,  6.80it/s]Batches:  86%|████████▌ | 455/532 [08:07<00:11,  6.64it/s]Batches:  86%|████████▌ | 456/532 [08:07<00:11,  6.57it/s]Batches:  86%|████████▌ | 457/532 [08:08<00:10,  6.86it/s]Batches:  86%|████████▌ | 458/532 [08:08<00:10,  6.82it/s]Batches:  86%|████████▋ | 459/532 [08:08<00:10,  7.07it/s]Batches:  86%|████████▋ | 460/532 [08:08<00:09,  7.22it/s]Batches:  87%|████████▋ | 461/532 [08:08<00:10,  6.95it/s]Batches:  87%|████████▋ | 462/532 [08:08<00:09,  7.08it/s]Batches:  87%|████████▋ | 463/532 [08:08<00:09,  7.22it/s]Batches:  87%|████████▋ | 464/532 [08:09<00:09,  7.26it/s]Batches:  87%|████████▋ | 465/532 [08:09<00:09,  6.95it/s]Batches:  88%|████████▊ | 466/532 [08:09<00:09,  7.11it/s]Batches:  88%|████████▊ | 467/532 [08:09<00:09,  7.22it/s]Batches:  88%|████████▊ | 468/532 [08:09<00:08,  7.33it/s]Batches:  88%|████████▊ | 469/532 [08:09<00:09,  6.99it/s]Batches:  88%|████████▊ | 470/532 [08:09<00:09,  6.78it/s]Batches:  89%|████████▊ | 471/532 [08:10<00:09,  6.66it/s]Batches:  89%|████████▊ | 472/532 [08:10<00:08,  6.71it/s]Batches:  89%|████████▉ | 473/532 [08:10<00:08,  6.90it/s]Batches:  89%|████████▉ | 474/532 [08:10<00:08,  6.87it/s]Batches:  89%|████████▉ | 475/532 [08:10<00:08,  6.82it/s]Batches:  89%|████████▉ | 476/532 [08:10<00:07,  7.07it/s]Batches:  90%|████████▉ | 477/532 [08:10<00:07,  7.20it/s]Batches:  90%|████████▉ | 478/532 [08:11<00:07,  7.43it/s]Batches:  90%|█████████ | 479/532 [08:11<00:07,  7.45it/s]Batches:  90%|█████████ | 480/532 [08:11<00:06,  7.53it/s]Batches:  90%|█████████ | 481/532 [08:11<00:06,  7.54it/s]Batches:  91%|█████████ | 482/532 [08:11<00:06,  7.71it/s]Batches:  91%|█████████ | 483/532 [08:11<00:06,  8.16it/s]Batches:  91%|█████████ | 484/532 [08:11<00:05,  8.13it/s]Batches:  91%|█████████ | 485/532 [08:11<00:05,  8.01it/s]Batches:  91%|█████████▏| 486/532 [08:11<00:05,  8.35it/s]Batches:  92%|█████████▏| 487/532 [08:12<00:05,  8.62it/s]Batches:  92%|█████████▏| 488/532 [08:12<00:05,  8.42it/s]Batches:  92%|█████████▏| 489/532 [08:12<00:04,  8.81it/s]Batches:  92%|█████████▏| 490/532 [08:12<00:04,  8.52it/s]Batches:  92%|█████████▏| 491/532 [08:12<00:04,  8.34it/s]Batches:  92%|█████████▏| 492/532 [08:12<00:04,  8.08it/s]Batches:  93%|█████████▎| 493/532 [08:12<00:04,  7.96it/s]Batches:  93%|█████████▎| 494/532 [08:12<00:04,  7.95it/s]Batches:  93%|█████████▎| 495/532 [08:13<00:04,  8.30it/s]Batches:  93%|█████████▎| 496/532 [08:13<00:04,  8.25it/s]Batches:  93%|█████████▎| 497/532 [08:13<00:04,  8.17it/s]Batches:  94%|█████████▎| 498/532 [08:13<00:04,  8.48it/s]Batches:  94%|█████████▍| 499/532 [08:13<00:04,  8.06it/s]Batches:  94%|█████████▍| 500/532 [08:13<00:03,  8.52it/s]Batches:  94%|█████████▍| 501/532 [08:13<00:03,  8.74it/s]Batches:  94%|█████████▍| 502/532 [08:13<00:03,  9.06it/s]Batches:  95%|█████████▍| 504/532 [08:14<00:02,  9.49it/s]Batches:  95%|█████████▍| 505/532 [08:14<00:02,  9.59it/s]Batches:  95%|█████████▌| 507/532 [08:14<00:02,  9.75it/s]Batches:  95%|█████████▌| 508/532 [08:14<00:02,  9.29it/s]Batches:  96%|█████████▌| 509/532 [08:14<00:02,  9.41it/s]Batches:  96%|█████████▌| 511/532 [08:14<00:02,  9.65it/s]Batches:  96%|█████████▋| 513/532 [08:15<00:01,  9.76it/s]Batches:  97%|█████████▋| 515/532 [08:15<00:01,  9.91it/s]Batches:  97%|█████████▋| 516/532 [08:15<00:01,  9.90it/s]Batches:  97%|█████████▋| 518/532 [08:15<00:01, 10.28it/s]Batches:  98%|█████████▊| 520/532 [08:15<00:01, 10.21it/s]Batches:  98%|█████████▊| 522/532 [08:15<00:00, 10.31it/s]Batches:  98%|█████████▊| 524/532 [08:16<00:00, 10.42it/s]Batches:  99%|█████████▉| 526/532 [08:16<00:00, 10.64it/s]Batches:  99%|█████████▉| 528/532 [08:16<00:00, 10.99it/s]Batches: 100%|█████████▉| 530/532 [08:16<00:00, 11.43it/s]Batches: 100%|██████████| 532/532 [08:16<00:00, 12.00it/s]Batches: 100%|██████████| 532/532 [08:16<00:00,  1.07it/s]
Time taken to retrieve: 505.03 seconds
2025-07-10 20:47:29 - Retriever evaluation for k in: [1, 3, 5, 10, 100, 1000]
2025-07-10 20:47:29 - For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
2025-07-10 20:47:29 - 

2025-07-10 20:47:29 - NDCG@1: 0.0966
2025-07-10 20:47:29 - NDCG@3: 0.1188
2025-07-10 20:47:29 - NDCG@5: 0.1333
2025-07-10 20:47:29 - NDCG@10: 0.1510
2025-07-10 20:47:29 - NDCG@100: 0.1807
2025-07-10 20:47:29 - NDCG@1000: 0.2005
2025-07-10 20:47:29 - 

2025-07-10 20:47:29 - MAP@1: 0.0753
2025-07-10 20:47:29 - MAP@3: 0.1026
2025-07-10 20:47:29 - MAP@5: 0.1102
2025-07-10 20:47:29 - MAP@10: 0.1172
2025-07-10 20:47:29 - MAP@100: 0.1221
2025-07-10 20:47:29 - MAP@1000: 0.1228
2025-07-10 20:47:29 - 

2025-07-10 20:47:29 - Recall@1: 0.0753
2025-07-10 20:47:29 - Recall@3: 0.1357
2025-07-10 20:47:29 - Recall@5: 0.1704
2025-07-10 20:47:29 - Recall@10: 0.2199
2025-07-10 20:47:29 - Recall@100: 0.3452
2025-07-10 20:47:29 - Recall@1000: 0.4833
2025-07-10 20:47:29 - 

2025-07-10 20:47:29 - P@1: 0.0966
2025-07-10 20:47:29 - P@3: 0.0595
2025-07-10 20:47:29 - P@5: 0.0446
2025-07-10 20:47:29 - P@10: 0.0297
2025-07-10 20:47:29 - P@100: 0.0052
2025-07-10 20:47:29 - P@1000: 0.0008
2025-07-10 20:47:29 - 

2025-07-10 20:47:29 - MRR@1: 0.0966
2025-07-10 20:47:29 - MRR@3: 0.1332
2025-07-10 20:47:29 - MRR@5: 0.1431
2025-07-10 20:47:29 - MRR@10: 0.1525
2025-07-10 20:47:29 - MRR@100: 0.1601
2025-07-10 20:47:29 - MRR@1000: 0.1606
2025-07-10 20:47:29 - 

2025-07-10 20:47:29 - R_cap@1: 0.0966
2025-07-10 20:47:29 - R_cap@3: 0.1363
2025-07-10 20:47:29 - R_cap@5: 0.1704
2025-07-10 20:47:29 - R_cap@10: 0.2199
2025-07-10 20:47:29 - R_cap@100: 0.3452
2025-07-10 20:47:29 - R_cap@1000: 0.4833
2025-07-10 20:47:29 - 

2025-07-10 20:47:29 - Hole@1: 0.8625
2025-07-10 20:47:29 - Hole@3: 0.8972
2025-07-10 20:47:29 - Hole@5: 0.9130
2025-07-10 20:47:29 - Hole@10: 0.9346
2025-07-10 20:47:29 - Hole@100: 0.9736
2025-07-10 20:47:29 - Hole@1000: 0.9889
2025-07-10 20:47:29 - Query : Problem:
What is the equivalent of R's ecdf(x)(x) function in Python, in either numpy or scipy? Is ecdf(x)(x) basically the same as:
import numpy as np
def ecdf(x):
  # normalize X to sum to 1
  x = x / np.sum(x)
  return np.cumsum(x)
or is something else required? 
Further, I want to compute the longest interval [low, high) that satisfies ECDF(x) < threshold for any x in [low, high). Note that low, high are elements of original array.
A:
<code>
import numpy as np
grades = np.array((93.5,93,60.8,94.5,82,87.5,91.5,99.5,86,93.5,92.5,78,76,69,94.5,
          89.5,92.8,78,65.5,98,98.5,92.3,95.5,76,91,95,61))
threshold = 0.5
</code>
low, high = ... # put solution in these variables
BEGIN SOLUTION
<code>


2025-07-10 20:47:29 - Rank 1: 13239 [skimage.api.skimage.filters#skimage.filters.apply_hysteresis_threshold] - skimage.filters.apply_hysteresis_threshold(image, low, high) [source]
 
Apply hysteresis thresholding to image. This algorithm finds regions where image is greater than high OR image is greater than low and that region is connected to a region greater than high.  Parameters 
 
imagearray, shape (M,[ N, …, P]) 

Grayscale input image.  
lowfloat, or array of same shape as image 

Lower threshold.  
highfloat, or array of same shape as image 

Higher threshold.    Returns 
 
thresholdedarray of bool, same shape as image 

Array in which True indicates the locations where image was above the hysteresis threshold.     References  
1  
J. Canny. A computational approach to edge detection. IEEE Transactions on Pattern Analysis and Machine Intelligence. 1986; vol. 8, pp.679-698. DOI:10.1109/TPAMI.1986.4767851   Examples >>> image = np.array([1, 2, 3, 2, 1, 2, 1, 3, 2])
>>> apply_hysteresis_threshold(image, 1.5, 2.5).astype(int)
array([0, 1, 1, 1, 0, 0, 0, 1, 1])

2025-07-10 20:47:29 - Rank 2: 9342 [sklearn.modules.generated.sklearn.preprocessing.labelbinarizer#sklearn.preprocessing.LabelBinarizer.inverse_transform] - inverse_transform(Y, threshold=None) [source]
 
Transform binary labels back to multi-class labels.  Parameters 
 
Y{ndarray, sparse matrix} of shape (n_samples, n_classes) 

Target values. All sparse matrices are converted to CSR before inverse transformation.  
thresholdfloat, default=None 

Threshold used in the binary and multi-label cases. Use 0 when Y contains the output of decision_function (classifier). Use 0.5 when Y contains the output of predict_proba. If None, the threshold is assumed to be half way between neg_label and pos_label.    Returns 
 
y{ndarray, sparse matrix} of shape (n_samples,) 

Target values. Sparse matrix will be of CSR format.     Notes In the case when the binary labels are fractional (probabilistic), inverse_transform chooses the class with the greatest value. Typically, this allows to use the output of a linear model’s decision_function method directly as the input of inverse_transform.

2025-07-10 20:47:29 - Rank 3: 8796 [sklearn.modules.generated.sklearn.metrics.det_curve#sklearn.metrics.det_curve] - sklearn.metrics.det_curve(y_true, y_score, pos_label=None, sample_weight=None) [source]
 
Compute error rates for different probability thresholds.  Note This metric is used for evaluation of ranking and error tradeoffs of a binary classification task.  Read more in the User Guide.  New in version 0.24.   Parameters 
 
y_truendarray of shape (n_samples,) 

True binary labels. If labels are not either {-1, 1} or {0, 1}, then pos_label should be explicitly given.  
y_scorendarray of shape of (n_samples,) 

Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions (as returned by “decision_function” on some classifiers).  
pos_labelint or str, default=None 

The label of the positive class. When pos_label=None, if y_true is in {-1, 1} or {0, 1}, pos_label is set to 1, otherwise an error will be raised.  
sample_weightarray-like of shape (n_samples,), default=None 

Sample weights.    Returns 
 
fprndarray of shape (n_thresholds,) 

False positive rate (FPR) such that element i is the false positive rate of predictions with score >= thresholds[i]. This is occasionally referred to as false acceptance propability or fall-out.  
fnrndarray of shape (n_thresholds,) 

False negative rate (FNR) such that element i is the false negative rate of predictions with score >= thresholds[i]. This is occasionally referred to as false rejection or miss rate.  
thresholdsndarray of shape (n_thresholds,) 

Decreasing score values.      See also  
plot_det_curve


Plot detection error tradeoff (DET) curve.  
DetCurveDisplay


DET curve visualization.  
roc_curve


Compute Receiver operating characteristic (ROC) curve.  
precision_recall_curve


Compute precision-recall curve.    Examples >>> import numpy as np
>>> from sklearn.metrics import det_curve
>>> y_true = np.array([0, 0, 1, 1])
>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])
>>> fpr, fnr, thresholds = det_curve(y_true, y_scores)
>>> fpr
array([0.5, 0.5, 0. ])
>>> fnr
array([0. , 0.5, 0.5])
>>> thresholds
array([0.35, 0.4 , 0.8 ])

