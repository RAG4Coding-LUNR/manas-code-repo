nohup: ignoring input
🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.
🦥 Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.6.12: Fast Llama patching. Transformers: 4.53.1.
   \\   /|    NVIDIA RTX A6000. Num GPUs = 1. Max memory: 47.413 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.51it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.74it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.81it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]
Unsloth 2025.6.12 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Starting fine-tuning: Unsloth/Codellama-7b...
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 2,000 | Num Epochs = 5 | Total steps = 315
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 32
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 32 x 1) = 32
 "-____-"     Trainable parameters = 79,953,920 of 6,818,500,608 (1.17% trained)
wandb: Currently logged in as: anshumaan-singh (anshumaan-singh-stony-brook-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /home/avisingh/retrieval/wandb/run-20250718_214751-v5s850bb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unsloth-finetune-11084637.530360801
wandb: ⭐️ View project at https://wandb.ai/anshumaan-singh-stony-brook-university/Unsloth-CodeLlama-RAG
wandb: 🚀 View run at https://wandb.ai/anshumaan-singh-stony-brook-university/Unsloth-CodeLlama-RAG/runs/v5s850bb
  0%|          | 0/315 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!
  0%|          | 1/315 [00:18<1:35:00, 18.16s/it]  1%|          | 2/315 [00:36<1:34:37, 18.14s/it]  1%|          | 3/315 [00:54<1:34:42, 18.21s/it]  1%|▏         | 4/315 [01:13<1:34:50, 18.30s/it]  2%|▏         | 5/315 [01:31<1:34:28, 18.29s/it]  2%|▏         | 6/315 [01:49<1:34:28, 18.34s/it]  2%|▏         | 7/315 [02:08<1:34:36, 18.43s/it]  3%|▎         | 8/315 [02:26<1:34:36, 18.49s/it]  3%|▎         | 9/315 [02:45<1:34:30, 18.53s/it]  3%|▎         | 10/315 [03:04<1:34:20, 18.56s/it]                                                  {'loss': 1.1793, 'grad_norm': 0.14318226277828217, 'learning_rate': 1.4062500000000001e-05, 'epoch': 0.16}
  3%|▎         | 10/315 [03:04<1:34:20, 18.56s/it]  3%|▎         | 11/315 [03:22<1:34:05, 18.57s/it]  4%|▍         | 12/315 [03:41<1:33:52, 18.59s/it]  4%|▍         | 13/315 [03:59<1:33:16, 18.53s/it]  4%|▍         | 14/315 [04:18<1:33:02, 18.55s/it]  5%|▍         | 15/315 [04:36<1:32:40, 18.54s/it]  5%|▌         | 16/315 [04:55<1:32:01, 18.47s/it]  5%|▌         | 17/315 [05:13<1:31:53, 18.50s/it]  6%|▌         | 18/315 [05:32<1:31:45, 18.54s/it]  6%|▌         | 19/315 [05:51<1:31:30, 18.55s/it]  6%|▋         | 20/315 [06:09<1:31:20, 18.58s/it]                                                  {'loss': 1.1754, 'grad_norm': 0.2709079682826996, 'learning_rate': 2.96875e-05, 'epoch': 0.32}
  6%|▋         | 20/315 [06:09<1:31:20, 18.58s/it]  7%|▋         | 21/315 [06:28<1:31:02, 18.58s/it]  7%|▋         | 22/315 [06:46<1:30:48, 18.60s/it]  7%|▋         | 23/315 [07:05<1:30:29, 18.59s/it]  8%|▊         | 24/315 [07:24<1:30:14, 18.61s/it]  8%|▊         | 25/315 [07:42<1:29:43, 18.57s/it]  8%|▊         | 26/315 [08:01<1:29:29, 18.58s/it]  9%|▊         | 27/315 [08:19<1:29:04, 18.56s/it]  9%|▉         | 28/315 [08:38<1:28:52, 18.58s/it]  9%|▉         | 29/315 [08:56<1:28:30, 18.57s/it] 10%|▉         | 30/315 [09:15<1:28:18, 18.59s/it]                                                  {'loss': 1.0799, 'grad_norm': 0.22481375932693481, 'learning_rate': 4.5312500000000004e-05, 'epoch': 0.48}
 10%|▉         | 30/315 [09:15<1:28:18, 18.59s/it] 10%|▉         | 31/315 [09:33<1:27:35, 18.51s/it] 10%|█         | 32/315 [09:52<1:27:13, 18.49s/it] 10%|█         | 33/315 [10:10<1:27:03, 18.52s/it] 11%|█         | 34/315 [10:29<1:26:43, 18.52s/it] 11%|█         | 35/315 [10:47<1:26:31, 18.54s/it] 11%|█▏        | 36/315 [11:06<1:26:16, 18.56s/it] 12%|█▏        | 37/315 [11:25<1:25:58, 18.56s/it] 12%|█▏        | 38/315 [11:43<1:25:42, 18.57s/it] 12%|█▏        | 39/315 [12:02<1:25:17, 18.54s/it] 13%|█▎        | 40/315 [12:20<1:25:02, 18.56s/it]                                                  {'loss': 0.9937, 'grad_norm': 0.12115714699029922, 'learning_rate': 4.9924557787092216e-05, 'epoch': 0.64}
 13%|█▎        | 40/315 [12:20<1:25:02, 18.56s/it] 13%|█▎        | 41/315 [12:39<1:24:47, 18.57s/it] 13%|█▎        | 42/315 [12:57<1:24:13, 18.51s/it] 14%|█▎        | 43/315 [13:16<1:24:00, 18.53s/it] 14%|█▍        | 44/315 [13:34<1:23:47, 18.55s/it] 14%|█▍        | 45/315 [13:53<1:23:33, 18.57s/it] 15%|█▍        | 46/315 [14:12<1:23:10, 18.55s/it] 15%|█▍        | 47/315 [14:30<1:22:55, 18.56s/it] 15%|█▌        | 48/315 [14:49<1:22:39, 18.58s/it] 16%|█▌        | 49/315 [15:07<1:21:42, 18.43s/it] 16%|█▌        | 50/315 [15:25<1:21:36, 18.48s/it]                                                  {'loss': 0.9946, 'grad_norm': 0.17266355454921722, 'learning_rate': 4.95561405997924e-05, 'epoch': 0.8}
 16%|█▌        | 50/315 [15:25<1:21:36, 18.48s/it] 16%|█▌        | 51/315 [15:44<1:21:27, 18.51s/it] 17%|█▋        | 52/315 [16:03<1:21:14, 18.54s/it] 17%|█▋        | 53/315 [16:21<1:20:18, 18.39s/it] 17%|█▋        | 54/315 [16:39<1:20:08, 18.42s/it] 17%|█▋        | 55/315 [16:58<1:19:58, 18.46s/it] 18%|█▊        | 56/315 [17:16<1:19:48, 18.49s/it] 18%|█▊        | 57/315 [17:35<1:19:35, 18.51s/it] 18%|█▊        | 58/315 [17:53<1:19:00, 18.45s/it] 19%|█▊        | 59/315 [18:12<1:18:49, 18.47s/it] 19%|█▉        | 60/315 [18:30<1:18:36, 18.49s/it]                                                  {'loss': 0.9247, 'grad_norm': 0.11754614859819412, 'learning_rate': 4.8885421465062236e-05, 'epoch': 0.96}
 19%|█▉        | 60/315 [18:30<1:18:36, 18.49s/it] 19%|█▉        | 61/315 [18:49<1:18:15, 18.49s/it] 20%|█▉        | 62/315 [19:07<1:18:03, 18.51s/it] 20%|██        | 63/315 [19:16<1:05:59, 15.71s/it] 20%|██        | 64/315 [19:35<1:09:15, 16.55s/it] 21%|██        | 65/315 [19:53<1:11:28, 17.15s/it] 21%|██        | 66/315 [20:12<1:12:56, 17.58s/it] 21%|██▏       | 67/315 [20:30<1:13:36, 17.81s/it] 22%|██▏       | 68/315 [20:49<1:14:10, 18.02s/it] 22%|██▏       | 69/315 [21:07<1:14:32, 18.18s/it] 22%|██▏       | 70/315 [21:26<1:14:36, 18.27s/it]                                                  {'loss': 0.8756, 'grad_norm': 0.14502166211605072, 'learning_rate': 4.7920657368554e-05, 'epoch': 1.11}
 22%|██▏       | 70/315 [21:26<1:14:36, 18.27s/it] 23%|██▎       | 71/315 [21:44<1:14:34, 18.34s/it] 23%|██▎       | 72/315 [22:03<1:14:31, 18.40s/it] 23%|██▎       | 73/315 [22:22<1:14:23, 18.44s/it] 23%|██▎       | 74/315 [22:40<1:14:08, 18.46s/it] 24%|██▍       | 75/315 [22:59<1:13:56, 18.49s/it] 24%|██▍       | 76/315 [23:17<1:13:40, 18.50s/it] 24%|██▍       | 77/315 [23:36<1:13:23, 18.50s/it] 25%|██▍       | 78/315 [23:54<1:13:08, 18.52s/it] 25%|██▌       | 79/315 [24:13<1:12:51, 18.52s/it] 25%|██▌       | 80/315 [24:31<1:12:35, 18.53s/it]                                                  {'loss': 0.8986, 'grad_norm': 0.46557506918907166, 'learning_rate': 4.667372517927323e-05, 'epoch': 1.27}
 25%|██▌       | 80/315 [24:31<1:12:35, 18.53s/it] 26%|██▌       | 81/315 [24:50<1:12:14, 18.52s/it] 26%|██▌       | 82/315 [25:08<1:11:37, 18.45s/it] 26%|██▋       | 83/315 [25:27<1:11:25, 18.47s/it] 27%|██▋       | 84/315 [25:45<1:11:07, 18.47s/it] 27%|██▋       | 85/315 [26:04<1:10:50, 18.48s/it] 27%|██▋       | 86/315 [26:22<1:10:37, 18.51s/it] 28%|██▊       | 87/315 [26:41<1:10:21, 18.51s/it] 28%|██▊       | 88/315 [26:59<1:09:51, 18.47s/it] 28%|██▊       | 89/315 [27:18<1:09:36, 18.48s/it] 29%|██▊       | 90/315 [27:36<1:09:09, 18.44s/it]                                                  {'loss': 0.8472, 'grad_norm': 0.23550894856452942, 'learning_rate': 4.5159975437652017e-05, 'epoch': 1.43}
 29%|██▊       | 90/315 [27:36<1:09:09, 18.44s/it] 29%|██▉       | 91/315 [27:54<1:08:56, 18.47s/it] 29%|██▉       | 92/315 [28:13<1:08:46, 18.50s/it] 30%|██▉       | 93/315 [28:31<1:08:19, 18.46s/it] 30%|██▉       | 94/315 [28:50<1:08:06, 18.49s/it] 30%|███       | 95/315 [29:08<1:07:32, 18.42s/it] 30%|███       | 96/315 [29:27<1:07:19, 18.45s/it] 31%|███       | 97/315 [29:45<1:07:05, 18.47s/it] 31%|███       | 98/315 [30:04<1:06:52, 18.49s/it] 31%|███▏      | 99/315 [30:22<1:06:32, 18.48s/it] 32%|███▏      | 100/315 [30:41<1:06:04, 18.44s/it]                                                   {'loss': 0.8075, 'grad_norm': 0.22664391994476318, 'learning_rate': 4.3398043380483965e-05, 'epoch': 1.59}
 32%|███▏      | 100/315 [30:41<1:06:04, 18.44s/it]wandb: WARNING The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
wandb: Adding directory to artifact (/home/avisingh/models/codellama-RAG-v1/checkpoint-100)... Done. 9.5s
 32%|███▏      | 101/315 [31:16<1:23:50, 23.51s/it] 32%|███▏      | 102/315 [31:34<1:18:02, 21.98s/it] 33%|███▎      | 103/315 [31:53<1:13:59, 20.94s/it] 33%|███▎      | 104/315 [32:11<1:10:51, 20.15s/it] 33%|███▎      | 105/315 [32:29<1:08:22, 19.54s/it] 34%|███▎      | 106/315 [32:48<1:07:05, 19.26s/it] 34%|███▍      | 107/315 [33:06<1:06:04, 19.06s/it] 34%|███▍      | 108/315 [33:25<1:05:17, 18.92s/it] 35%|███▍      | 109/315 [33:44<1:04:38, 18.83s/it] 35%|███▍      | 110/315 [34:02<1:03:59, 18.73s/it]                                                   {'loss': 0.8987, 'grad_norm': 0.1417206972837448, 'learning_rate': 4.140961952912594e-05, 'epoch': 1.75}
 35%|███▍      | 110/315 [34:02<1:03:59, 18.73s/it] 35%|███▌      | 111/315 [34:21<1:03:32, 18.69s/it] 36%|███▌      | 112/315 [34:39<1:03:02, 18.63s/it] 36%|███▌      | 113/315 [34:58<1:02:35, 18.59s/it] 36%|███▌      | 114/315 [35:16<1:02:01, 18.52s/it] 37%|███▋      | 115/315 [35:35<1:01:45, 18.53s/it] 37%|███▋      | 116/315 [35:53<1:01:32, 18.55s/it] 37%|███▋      | 117/315 [36:12<1:01:09, 18.53s/it] 37%|███▋      | 118/315 [36:30<1:00:54, 18.55s/it] 38%|███▊      | 119/315 [36:49<1:00:29, 18.52s/it] 38%|███▊      | 120/315 [37:07<1:00:15, 18.54s/it]                                                   {'loss': 0.8283, 'grad_norm': 0.1824076920747757, 'learning_rate': 3.921918266517391e-05, 'epoch': 1.91}
 38%|███▊      | 120/315 [37:07<1:00:15, 18.54s/it] 38%|███▊      | 121/315 [37:26<59:57, 18.54s/it]   39%|███▊      | 122/315 [37:44<59:40, 18.55s/it] 39%|███▉      | 123/315 [38:03<59:13, 18.51s/it] 39%|███▉      | 124/315 [38:21<59:00, 18.54s/it] 40%|███▉      | 125/315 [38:40<58:35, 18.50s/it] 40%|████      | 126/315 [38:49<49:34, 15.74s/it] 40%|████      | 127/315 [39:08<51:57, 16.58s/it] 41%|████      | 128/315 [39:26<53:33, 17.19s/it] 41%|████      | 129/315 [39:45<54:31, 17.59s/it] 41%|████▏     | 130/315 [40:03<55:09, 17.89s/it]                                                 {'loss': 0.8003, 'grad_norm': 0.16931821405887604, 'learning_rate': 3.6853698480854855e-05, 'epoch': 2.06}
 41%|████▏     | 130/315 [40:03<55:09, 17.89s/it] 42%|████▏     | 131/315 [40:22<55:22, 18.06s/it] 42%|████▏     | 132/315 [40:40<55:33, 18.22s/it] 42%|████▏     | 133/315 [40:59<55:30, 18.30s/it] 43%|████▎     | 134/315 [41:18<55:28, 18.39s/it] 43%|████▎     | 135/315 [41:36<55:04, 18.36s/it] 43%|████▎     | 136/315 [41:54<54:56, 18.42s/it] 43%|████▎     | 137/315 [42:13<54:31, 18.38s/it] 44%|████▍     | 138/315 [42:31<54:24, 18.44s/it] 44%|████▍     | 139/315 [42:50<54:09, 18.46s/it] 44%|████▍     | 140/315 [43:08<53:51, 18.47s/it]                                                 {'loss': 0.743, 'grad_norm': 0.1548556685447693, 'learning_rate': 3.4342287613942805e-05, 'epoch': 2.22}
 44%|████▍     | 140/315 [43:08<53:51, 18.47s/it] 45%|████▍     | 141/315 [43:27<53:27, 18.43s/it] 45%|████▌     | 142/315 [43:45<53:10, 18.44s/it] 45%|████▌     | 143/315 [44:04<52:57, 18.48s/it] 46%|████▌     | 144/315 [44:22<52:43, 18.50s/it] 46%|████▌     | 145/315 [44:41<52:28, 18.52s/it] 46%|████▋     | 146/315 [44:59<52:12, 18.54s/it] 47%|████▋     | 147/315 [45:18<51:54, 18.54s/it] 47%|████▋     | 148/315 [45:36<51:34, 18.53s/it] 47%|████▋     | 149/315 [45:55<51:07, 18.48s/it] 48%|████▊     | 150/315 [46:13<50:52, 18.50s/it]                                                 {'loss': 0.7848, 'grad_norm': 0.1439443677663803, 'learning_rate': 3.171586715390384e-05, 'epoch': 2.38}
 48%|████▊     | 150/315 [46:13<50:52, 18.50s/it] 48%|████▊     | 151/315 [46:32<50:35, 18.51s/it] 48%|████▊     | 152/315 [46:50<50:14, 18.49s/it] 49%|████▊     | 153/315 [47:09<49:57, 18.50s/it] 49%|████▉     | 154/315 [47:27<49:40, 18.51s/it] 49%|████▉     | 155/315 [47:46<49:23, 18.52s/it] 50%|████▉     | 156/315 [48:04<49:07, 18.53s/it] 50%|████▉     | 157/315 [48:23<48:47, 18.53s/it] 50%|█████     | 158/315 [48:42<48:30, 18.54s/it] 50%|█████     | 159/315 [49:00<48:11, 18.53s/it] 51%|█████     | 160/315 [49:19<47:51, 18.52s/it]                                                 {'loss': 0.7537, 'grad_norm': 0.14743293821811676, 'learning_rate': 2.9006770032560637e-05, 'epoch': 2.54}
 51%|█████     | 160/315 [49:19<47:51, 18.52s/it] 51%|█████     | 161/315 [49:37<47:32, 18.52s/it] 51%|█████▏    | 162/315 [49:56<47:14, 18.53s/it] 52%|█████▏    | 163/315 [50:14<46:44, 18.45s/it] 52%|█████▏    | 164/315 [50:32<46:25, 18.45s/it] 52%|█████▏    | 165/315 [50:51<46:06, 18.44s/it] 53%|█████▎    | 166/315 [51:09<45:52, 18.47s/it] 53%|█████▎    | 167/315 [51:28<45:25, 18.42s/it] 53%|█████▎    | 168/315 [51:46<45:13, 18.46s/it] 54%|█████▎    | 169/315 [52:05<44:59, 18.49s/it] 54%|█████▍    | 170/315 [52:23<44:43, 18.51s/it]                                                 {'loss': 0.8043, 'grad_norm': 0.15568876266479492, 'learning_rate': 2.6248346984823324e-05, 'epoch': 2.7}
 54%|█████▍    | 170/315 [52:23<44:43, 18.51s/it] 54%|█████▍    | 171/315 [52:42<44:27, 18.53s/it] 55%|█████▍    | 172/315 [53:00<44:11, 18.54s/it] 55%|█████▍    | 173/315 [53:19<43:51, 18.53s/it] 55%|█████▌    | 174/315 [53:37<43:34, 18.54s/it] 56%|█████▌    | 175/315 [53:55<42:49, 18.35s/it] 56%|█████▌    | 176/315 [54:14<42:39, 18.42s/it] 56%|█████▌    | 177/315 [54:33<42:27, 18.46s/it] 57%|█████▋    | 178/315 [54:51<42:10, 18.47s/it] 57%|█████▋    | 179/315 [55:09<41:51, 18.47s/it] 57%|█████▋    | 180/315 [55:28<41:37, 18.50s/it]                                                 {'loss': 0.7942, 'grad_norm': 0.15179648995399475, 'learning_rate': 2.3474555979607214e-05, 'epoch': 2.86}
 57%|█████▋    | 180/315 [55:28<41:37, 18.50s/it] 57%|█████▋    | 181/315 [55:46<41:01, 18.37s/it] 58%|█████▊    | 182/315 [56:05<40:52, 18.44s/it] 58%|█████▊    | 183/315 [56:23<40:37, 18.46s/it] 58%|█████▊    | 184/315 [56:42<40:22, 18.49s/it] 59%|█████▊    | 185/315 [57:00<40:06, 18.51s/it] 59%|█████▉    | 186/315 [57:19<39:51, 18.54s/it] 59%|█████▉    | 187/315 [57:37<39:21, 18.45s/it] 60%|█████▉    | 188/315 [57:56<39:00, 18.43s/it] 60%|██████    | 189/315 [58:05<32:55, 15.68s/it] 60%|██████    | 190/315 [58:23<34:19, 16.48s/it]                                                 {'loss': 0.7679, 'grad_norm': 0.15925376117229462, 'learning_rate': 2.0719544175307754e-05, 'epoch': 3.02}
 60%|██████    | 190/315 [58:23<34:19, 16.48s/it] 61%|██████    | 191/315 [58:42<35:18, 17.08s/it] 61%|██████    | 192/315 [59:00<35:55, 17.52s/it] 61%|██████▏   | 193/315 [59:19<36:15, 17.83s/it] 62%|██████▏   | 194/315 [59:37<36:23, 18.05s/it] 62%|██████▏   | 195/315 [59:56<36:15, 18.13s/it] 62%|██████▏   | 196/315 [1:00:14<36:11, 18.25s/it] 63%|██████▎   | 197/315 [1:00:33<36:04, 18.34s/it] 63%|██████▎   | 198/315 [1:00:51<35:52, 18.40s/it] 63%|██████▎   | 199/315 [1:01:10<35:38, 18.43s/it] 63%|██████▎   | 200/315 [1:01:28<35:23, 18.47s/it]                                                   {'loss': 0.7814, 'grad_norm': 0.18298088014125824, 'learning_rate': 1.801722754623077e-05, 'epoch': 3.18}
 63%|██████▎   | 200/315 [1:01:28<35:23, 18.47s/it]wandb: Adding directory to artifact (/home/avisingh/models/codellama-RAG-v1/checkpoint-200)... Done. 9.3s
 64%|██████▍   | 201/315 [1:02:04<44:40, 23.51s/it] 64%|██████▍   | 202/315 [1:02:22<41:23, 21.98s/it] 64%|██████▍   | 203/315 [1:02:40<38:58, 20.88s/it] 65%|██████▍   | 204/315 [1:02:59<37:11, 20.10s/it] 65%|██████▌   | 205/315 [1:03:17<36:01, 19.65s/it] 65%|██████▌   | 206/315 [1:03:36<35:04, 19.31s/it] 66%|██████▌   | 207/315 [1:03:54<34:14, 19.02s/it] 66%|██████▌   | 208/315 [1:04:13<33:41, 18.89s/it] 66%|██████▋   | 209/315 [1:04:31<33:12, 18.80s/it] 67%|██████▋   | 210/315 [1:04:50<32:47, 18.74s/it]                                                   {'loss': 0.7266, 'grad_norm': 0.17476266622543335, 'learning_rate': 1.540087335504825e-05, 'epoch': 3.34}
 67%|██████▋   | 210/315 [1:04:50<32:47, 18.74s/it] 67%|██████▋   | 211/315 [1:05:08<32:24, 18.69s/it] 67%|██████▋   | 212/315 [1:05:27<32:02, 18.66s/it] 68%|██████▊   | 213/315 [1:05:46<31:38, 18.61s/it] 68%|██████▊   | 214/315 [1:06:04<31:17, 18.58s/it] 68%|██████▊   | 215/315 [1:06:23<30:58, 18.59s/it] 69%|██████▊   | 216/315 [1:06:41<30:39, 18.58s/it] 69%|██████▉   | 217/315 [1:07:00<30:21, 18.58s/it] 69%|██████▉   | 218/315 [1:07:18<30:00, 18.56s/it] 70%|██████▉   | 219/315 [1:07:37<29:40, 18.55s/it] 70%|██████▉   | 220/315 [1:07:55<29:06, 18.39s/it]                                                   {'loss': 0.761, 'grad_norm': 0.16713647544384003, 'learning_rate': 1.2902690611313135e-05, 'epoch': 3.5}
 70%|██████▉   | 220/315 [1:07:55<29:06, 18.39s/it] 70%|███████   | 221/315 [1:08:13<28:52, 18.43s/it] 70%|███████   | 222/315 [1:08:32<28:38, 18.48s/it] 71%|███████   | 223/315 [1:08:51<28:22, 18.50s/it] 71%|███████   | 224/315 [1:09:09<28:05, 18.52s/it] 71%|███████▏  | 225/315 [1:09:28<27:47, 18.53s/it] 72%|███████▏  | 226/315 [1:09:46<27:27, 18.51s/it] 72%|███████▏  | 227/315 [1:10:05<27:10, 18.52s/it] 72%|███████▏  | 228/315 [1:10:23<26:45, 18.46s/it] 73%|███████▎  | 229/315 [1:10:41<26:29, 18.49s/it] 73%|███████▎  | 230/315 [1:11:00<26:14, 18.52s/it]                                                   {'loss': 0.7595, 'grad_norm': 0.17130973935127258, 'learning_rate': 1.055343355775339e-05, 'epoch': 3.66}
 73%|███████▎  | 230/315 [1:11:00<26:14, 18.52s/it] 73%|███████▎  | 231/315 [1:11:19<25:53, 18.50s/it] 74%|███████▎  | 232/315 [1:11:37<25:33, 18.47s/it] 74%|███████▍  | 233/315 [1:11:55<25:08, 18.39s/it] 74%|███████▍  | 234/315 [1:12:14<24:54, 18.45s/it] 75%|███████▍  | 235/315 [1:12:32<24:38, 18.48s/it] 75%|███████▍  | 236/315 [1:12:51<24:17, 18.45s/it] 75%|███████▌  | 237/315 [1:13:09<24:01, 18.48s/it] 76%|███████▌  | 238/315 [1:13:28<23:44, 18.50s/it] 76%|███████▌  | 239/315 [1:13:46<23:27, 18.51s/it] 76%|███████▌  | 240/315 [1:14:05<23:09, 18.53s/it]                                                   {'loss': 0.7244, 'grad_norm': 0.1689508557319641, 'learning_rate': 8.38202306568507e-06, 'epoch': 3.82}
 76%|███████▌  | 240/315 [1:14:05<23:09, 18.53s/it] 77%|███████▋  | 241/315 [1:14:23<22:51, 18.53s/it] 77%|███████▋  | 242/315 [1:14:42<22:33, 18.54s/it] 77%|███████▋  | 243/315 [1:15:00<22:09, 18.46s/it] 77%|███████▋  | 244/315 [1:15:19<21:54, 18.51s/it] 78%|███████▊  | 245/315 [1:15:37<21:36, 18.52s/it] 78%|███████▊  | 246/315 [1:15:56<21:19, 18.54s/it] 78%|███████▊  | 247/315 [1:16:15<21:01, 18.54s/it] 79%|███████▊  | 248/315 [1:16:33<20:41, 18.53s/it] 79%|███████▉  | 249/315 [1:16:52<20:23, 18.54s/it] 79%|███████▉  | 250/315 [1:17:10<20:05, 18.55s/it]                                                   {'loss': 0.7345, 'grad_norm': 0.18762655556201935, 'learning_rate': 6.4151906004113385e-06, 'epoch': 3.98}
 79%|███████▉  | 250/315 [1:17:10<20:05, 18.55s/it] 80%|███████▉  | 251/315 [1:17:29<19:47, 18.55s/it] 80%|████████  | 252/315 [1:17:38<16:33, 15.77s/it] 80%|████████  | 253/315 [1:17:57<17:10, 16.62s/it] 81%|████████  | 254/315 [1:18:15<17:28, 17.19s/it] 81%|████████  | 255/315 [1:18:33<17:27, 17.45s/it] 81%|████████▏ | 256/315 [1:18:52<17:29, 17.79s/it] 82%|████████▏ | 257/315 [1:19:10<17:25, 18.03s/it] 82%|████████▏ | 258/315 [1:19:29<17:15, 18.17s/it] 82%|████████▏ | 259/315 [1:19:47<17:04, 18.29s/it] 83%|████████▎ | 260/315 [1:20:06<16:49, 18.35s/it]                                                   {'loss': 0.7198, 'grad_norm': 0.189912348985672, 'learning_rate': 4.6771491396232605e-06, 'epoch': 4.13}
 83%|████████▎ | 260/315 [1:20:06<16:49, 18.35s/it] 83%|████████▎ | 261/315 [1:20:25<16:34, 18.42s/it] 83%|████████▎ | 262/315 [1:20:43<16:16, 18.42s/it] 83%|████████▎ | 263/315 [1:21:02<16:00, 18.48s/it] 84%|████████▍ | 264/315 [1:21:20<15:43, 18.50s/it] 84%|████████▍ | 265/315 [1:21:39<15:26, 18.53s/it] 84%|████████▍ | 266/315 [1:21:57<15:08, 18.53s/it] 85%|████████▍ | 267/315 [1:22:16<14:50, 18.55s/it] 85%|████████▌ | 268/315 [1:22:34<14:31, 18.55s/it] 85%|████████▌ | 269/315 [1:22:53<14:12, 18.53s/it] 86%|████████▌ | 270/315 [1:23:11<13:54, 18.55s/it]                                                   {'loss': 0.7441, 'grad_norm': 0.17961150407791138, 'learning_rate': 3.189295096009376e-06, 'epoch': 4.29}
 86%|████████▌ | 270/315 [1:23:11<13:54, 18.55s/it] 86%|████████▌ | 271/315 [1:23:30<13:33, 18.50s/it] 86%|████████▋ | 272/315 [1:23:48<13:15, 18.51s/it] 87%|████████▋ | 273/315 [1:24:07<12:58, 18.53s/it] 87%|████████▋ | 274/315 [1:24:25<12:36, 18.46s/it] 87%|████████▋ | 275/315 [1:24:44<12:19, 18.49s/it] 88%|████████▊ | 276/315 [1:25:02<12:02, 18.52s/it] 88%|████████▊ | 277/315 [1:25:21<11:42, 18.48s/it] 88%|████████▊ | 278/315 [1:25:39<11:21, 18.43s/it] 89%|████████▊ | 279/315 [1:25:57<11:02, 18.39s/it] 89%|████████▉ | 280/315 [1:26:16<10:45, 18.45s/it]                                                   {'loss': 0.6813, 'grad_norm': 0.177080899477005, 'learning_rate': 1.969944913599181e-06, 'epoch': 4.45}
 89%|████████▉ | 280/315 [1:26:16<10:45, 18.45s/it] 89%|████████▉ | 281/315 [1:26:34<10:26, 18.41s/it] 90%|████████▉ | 282/315 [1:26:53<10:05, 18.36s/it] 90%|████████▉ | 283/315 [1:27:11<09:48, 18.40s/it] 90%|█████████ | 284/315 [1:27:30<09:31, 18.44s/it] 90%|█████████ | 285/315 [1:27:48<09:13, 18.46s/it] 91%|█████████ | 286/315 [1:28:06<08:54, 18.42s/it] 91%|█████████ | 287/315 [1:28:25<08:36, 18.45s/it] 91%|█████████▏| 288/315 [1:28:43<08:18, 18.46s/it] 92%|█████████▏| 289/315 [1:29:02<08:00, 18.50s/it] 92%|█████████▏| 290/315 [1:29:21<07:42, 18.52s/it]                                                   {'loss': 0.7681, 'grad_norm': 0.19018952548503876, 'learning_rate': 1.0341095805096485e-06, 'epoch': 4.61}
 92%|█████████▏| 290/315 [1:29:21<07:42, 18.52s/it] 92%|█████████▏| 291/315 [1:29:39<07:25, 18.55s/it] 93%|█████████▎| 292/315 [1:29:58<07:06, 18.55s/it] 93%|█████████▎| 293/315 [1:30:16<06:48, 18.57s/it] 93%|█████████▎| 294/315 [1:30:35<06:29, 18.57s/it] 94%|█████████▎| 295/315 [1:30:53<06:09, 18.49s/it] 94%|█████████▍| 296/315 [1:31:12<05:51, 18.52s/it] 94%|█████████▍| 297/315 [1:31:30<05:33, 18.51s/it] 95%|█████████▍| 298/315 [1:31:49<05:14, 18.52s/it] 95%|█████████▍| 299/315 [1:32:07<04:56, 18.56s/it] 95%|█████████▌| 300/315 [1:32:26<04:37, 18.52s/it]                                                   {'loss': 0.7362, 'grad_norm': 0.19194117188453674, 'learning_rate': 3.933098339884478e-07, 'epoch': 4.77}
 95%|█████████▌| 300/315 [1:32:26<04:37, 18.52s/it]wandb: Adding directory to artifact (/home/avisingh/models/codellama-RAG-v1/checkpoint-300)... Done. 8.7s
 96%|█████████▌| 301/315 [1:33:00<05:26, 23.32s/it] 96%|█████████▌| 302/315 [1:33:19<04:43, 21.84s/it] 96%|█████████▌| 303/315 [1:33:37<04:09, 20.81s/it] 97%|█████████▋| 304/315 [1:33:56<03:41, 20.12s/it] 97%|█████████▋| 305/315 [1:34:14<03:16, 19.65s/it] 97%|█████████▋| 306/315 [1:34:33<02:53, 19.32s/it] 97%|█████████▋| 307/315 [1:34:51<02:32, 19.08s/it] 98%|█████████▊| 308/315 [1:35:10<02:12, 18.90s/it] 98%|█████████▊| 309/315 [1:35:28<01:52, 18.80s/it] 98%|█████████▊| 310/315 [1:35:47<01:33, 18.72s/it]                                                   {'loss': 0.7597, 'grad_norm': 0.1899036467075348, 'learning_rate': 5.543433269915022e-08, 'epoch': 4.93}
 98%|█████████▊| 310/315 [1:35:47<01:33, 18.72s/it] 99%|█████████▊| 311/315 [1:36:06<01:14, 18.68s/it] 99%|█████████▉| 312/315 [1:36:24<00:55, 18.63s/it] 99%|█████████▉| 313/315 [1:36:43<00:37, 18.58s/it]100%|█████████▉| 314/315 [1:37:01<00:18, 18.58s/it]100%|██████████| 315/315 [1:37:10<00:00, 15.79s/it]wandb: Adding directory to artifact (/home/avisingh/models/codellama-RAG-v1/checkpoint-315)... Done. 9.3s
                                                   {'train_runtime': 5849.1204, 'train_samples_per_second': 1.71, 'train_steps_per_second': 0.054, 'train_loss': 0.8319730758666992, 'epoch': 5.0}
100%|██████████| 315/315 [1:37:27<00:00, 15.79s/it]Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
100%|██████████| 315/315 [1:37:29<00:00, 18.57s/it]
Training complete.
Model Saved
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33munsloth-finetune-11084637.530360801[0m at: [34mhttps://wandb.ai/anshumaan-singh-stony-brook-university/Unsloth-CodeLlama-RAG/runs/v5s850bb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250718_214751-v5s850bb/logs[0m
